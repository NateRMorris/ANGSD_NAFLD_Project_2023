---
title: "ANGSD_NAFLD_Project_Nathan_Morris"
output: html_document
date: "2023-03-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Introduction:

I. Introduction

Non-alcoholic 

I've selected samples from the paper: Hoang et al 2019, found below. https://link.springer.com/content/pdf/10.1038/s41598-019-48746-5.pdf. HemoShear Therapeutics generated the data. The RNA was extracted from cells using a Qiagen RNeasy RNA isolaion kit, which uses polyA-oligo-dT-based purification of mRNA. Illumina TruSeq Stranded mRNA Sample prep was used on liver biopsy cells from 72 patients covering the full spectrum of non-alcoholic fatty liver disease (NAFLD activity score of 0 to 6, fibrosis stage score of 0 to 4), while 6 histologically normal samples were used as well. Illumina HiSeq 2500 was used to sequence the material.

Here is more detailed information on each sample: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA542148&o=acc_s%3Aa

An estimated 22.5% of people aged 20 or older 

Methods:

1. Getting the FASTQ Files

I got a list of FASTQ files from the SRA Accession website and made the below csv, called sample_sras.csv.
I wanted to select samples from patients with similar profiles. Since older woman were most abundant in the study, I decided to take samples from woman over 58 years old with a range of conditions. In this study, I decided to include two conditions: HIGH NAFLD (NAFLD levels of 5 or 6) and LOW NAFLD (NAFLD levels mostly of 0 and 1 sample with 1). These NAFLD scores as well as the fibrosis stage. Fibrosis stage can be used as a prognosis for the seversity of NAFLD and has been shown to predict mortality and time to development of severe liver disease (https://pubmed.ncbi.nlm.nih.gov/32027911/, https://pubmed.ncbi.nlm.nih.gov/25935633/)
```
SRR9036307_1,
SRR9036307_2,
SRR9036311_1,
SRR9036311_2,
SRR9036380_1,
SRR9036380_2,
SRR9036314_1,
SRR9036314_2,
SRR9036377_1,
SRR9036377_2,
SRR9036379_1,
SRR9036379_2,
SRR9036384_1,
SRR9036384_2,
SRR9036357_1,
SRR9036357_2,
```
I've also supplied an NAFLD_Sample_Notes sheet, which gives the fibrosis stage and NAFLD scores for each patient's samples.
More detailed information on each sample can be found here: https://www.ncbi.nlm.nih.gov/Traces/study/?acc=PRJNA542148&o=acc_s%3Aa

The below bash script, called Download_fastqs.sh, takes the samples from the sample_sras.csv and downloads the necessary contents. This was the first executed command.
```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="wget_fastq_files"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=16G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Define the path to the CSV file
csv_file="sample_sras.csv"

# Loop through each line in the CSV file
for line in $(cat "$csv_file"); do
    string="${line::-2}"
    trimmed="${line::-4}"
    #echo $string
    #echo $trimmed
  # Use wget to download the URL specified in the current line
  wget ftp://ftp.sra.ebi.ac.uk/vol1/fastq/SRR903/007/$trimmed/$string.fastq.gz

done

echo 'Finished'
```

2. Rename FastQs

Next, I wanted to rename the fastqs to allow for more proper identification, and then run fastQC on them. Therefore, I made a secondary csv file with the new names, called new_names.csv. Below are the contents.
```
HIGH_NAFLD1_1,
HIGH_NAFLD1_2,
HIGH_NAFLD2_1,
HIGH_NAFLD2_2,
HIGH_NAFLD3_1,
HIGH_NAFLD3_2,
HIGH_NAFLD4_1,
HIGH_NAFLD4_2,
LOW_NAFLD1_1,
LOW_NAFLD1_2,
LOW_NAFLD2_1,
LOW_NAFLD2_2,
LOW_NAFLD3_1,
LOW_NAFLD3_2,
LOW_NAFLD4_1,
LOW_NAFLD4_2,
```
Then, I decided to make a script in order to rename the old fastq files to the new names. This code was the second to be executed. This is called rename_fastq.sh:
```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="rename_fastq"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=4G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

# Define the path to the CSV file
csv_file="sample_sras.csv"
csv_new_name="new_names.csv"

line_count=$(wc -l < $csv_file)
name_count=$(wc -l < $csv_new_name)

# Loop through each line in the CSV file
if [[ "$line_count" == "$name_count" ]]; then
    for line_num in `seq 1 $line_count`;
    do
        old_name=$(awk -F ',' "NR==$line_num" $csv_file) #SRR9036357_2
        new_name=$(awk -F ',' "NR==$line_num" $csv_new_name)
        old_name_trim=${old_name%??}
        new_name_trim=${new_name%?}
        #echo $old_name_trim
        #echo $new_name_trim
        # Use mv to rename the fastqfiles to our sample names
        mv /home/nam4021/project/project_org/fastqfiles/$old_name_trim.fastq.gz /home/nam4021/project/project_org/fastqfiles/$new_name_trim.fastq.gz
        #echo old: /home/nam4021/project/project_org/fastqfiles/$old_name_trim.fastq.gz
        #echo new: /home/nam4021/project/project_org/fastqfiles/$new_name_trim.fastq.gz
        #mv /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_2,.fastq.gz /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_2.fastq.gz
    done
else
    echo "CSV of Fastq files and new names are not the same length"
fi

## ONE ISSUE IS THE LAST NEW FILE NAME HAS A COMMA AT THE END, NEED TO MANUALLY CHANGE
mv /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_2,.fastq.gz /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_2.fastq.gz

echo 'Finished'
```
Unfortunately, due to the format of the csv file, I had to rename the LOW_NAFLD4_2,.fastq.gz file in the last stage of the for-loop as a correction. A high memory wasn't necessary for these commands, so the SBATCH parameters were limited to 1 node, 1 task and 4G. No other parameters were necessary in the actual loop and function.

3. FastQC - Sequence Quality Control

I also made a different script called fastqc_NAFLD.sh. These I manually input for each file, however a for loop would have been a more proper way to do so. Here, I used 8G in the SBATCH, but no further parameters were needed for fastqc besides the input file, the --extract since the fastq file is gzipped, and the out directory.
```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="fastqc"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=8G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

mamba activate angsd

fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD1_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD1_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD2_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD2_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD3_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD3_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD4_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/HIGH_NAFLD4_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD1_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD1_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD2_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD2_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD3_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD3_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_1.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
fastqc /home/nam4021/project/project_org/fastqfiles/LOW_NAFLD4_2.fastq.gz --extract --outdir /athena/angsd/scratch/nam4021/fastqc_NAFLD
```

4. STAR Indexing and Alignment

For this, I decided to build a new index for the GRCh38.p14 human genome. 

I found the necessary Genome sequence (FASTA) and annotation features (GFF) at the below websites:
https://www.ncbi.nlm.nih.gov/data-hub/genome/GCF_000001405.40/
https://ftp.ncbi.nlm.nih.gov/genomes/refseq/vertebrate_mammalian/Homo_sapiens/latest_assembly_versions/GCF_000001405.40_GRCh38.p14/. This gff file was recently updated in February 2022 and is version GRCh38.p14. It is also provided by the NCBI RefSeq. 

In the Hoang et al paper, GRCh37.75 from Ensembl was used, along with Salmon (run in a GC bias-aware mode), and using a TMM normalization method from edgeR. Finally, counts and normalized library sizes were used to transform gene-level counts into log2(CPM) values. My reference, alignment process and normalization methods were different, but I wanted to see if my results would still be consistent with the results from the paper. I also decided to use the genome assembly and annotations I chose due to the recent updates and the high amount of annotation, which later I realized isn't always the best way to annotate data.

Using the annotation and the sequence, I constructed and ran the below script. Unfortunately, I kept receiving the "Exceeded step memory limit at some point" error. Therefore, I had to use 64G and for the indexing to work.

I chose the following parameters based on --runThreadN 6 and --sjdbOverhang 99. This is so it will run in 6 different threads in parallel, and I've used the 99 overhang because it is the default value. The individual reads are 51 bp, therefore 99 overhand is fine, even though the database will be a bit larger than necessary. I've kept the number of nodes and tasks as the default (=1). Our gff file is still compatible with the --sjdbGTFfile command. This file is called Create_hg38_index.sh.
```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="genome_index"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=64G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

mamba activate angsd

echo 'Starting STAR indexing now'

STAR --runThreadN 6 --runMode genomeGenerate --genomeDir /athena/angsd/scratch/nam4021/hg38_Index --genomeFastaFiles /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40/GCF_000001405.40_GRCh38.p14_genomic.fna --sjdbGTFfile /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40/genomic.gff --sjdbOverhang 99

echo 'Finished'
```

Next, I decided to align these using the align_all_paired.sh file. I've used 2 nodes and 4 tasks in order to run the alignment in parallel with 34G. As described in the script below and due to the formatting of the csv's (as mentioned in the above re-name script), LOW_NAFLD4 had different parsing than the others from the new_names.csv. The runthread is set to 8, so it will run in parallel different threads. I've also used the gunzip readFilesCommand in order to use the fastq.gz files.

I realized after running this alignment, I could've used the genome.ucsc website (https://genome.ucsc.edu/cgi-bin/hgTables) in order to assess the Intron Minimum and input this factor. After selecting the proper genome assembly, .bed output file and select to create one BED record per Introns plus 0 bases at each end, I've gotten the introns.bed file included in my github datasets. You can run the below commands to extract the smallest and largest intron values.

Below gives us the smallest intron values: The results are- 1, 2, 10.
```
awk '{print $3 - $2} ' introns.bed | sort -n | uniq | head -n 3
```
Below gives us the largest intron values: The results are- 1160411, 1097903, 1068357
```
awk '{print $3 - $2} ' introns.bed | sort -rn | uniq | head -n 3
```
Therefore, in the future '''#--alignIntronMin 10  --alignIntronMax 1200000''' should be used

I also could've changed the outTmpDir, to use the scratch folder as the temporary directory that STAR uses to sort. If I re-run the samples, I'll be sure to include these parameters. I've included these as commented out sections in order to remember to include them, however they are not set to the optimal values for now.

```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=2
#SBATCH --ntasks=4
#SBATCH --job-name="align_fasta"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=36G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

echo 'Starting STAR alignment now'

# Define the path to the CSV file
csv_file="sample_sras.csv"
csv_new_name="new_names.csv"
### --readFilesIn LOW_NAFLD3_1.fastq.gz LOW_NAFLD3_2.fastq.gz OTHERS LOOK FINE
## --readFilesIn LOW_NAFLD4__1.fastq.gz LOW_NAFLD4__2.fastq.gz SOMEHOW NAFLD4 is doing this

# Loop through each line in the CSV file
#for line in $(cat "$csv_file"); do

for 
awk 'NR % 2 == 0' "$csv_new_name" | while read line
do
    string="${line::-2}"
    trimmed="${line::-3}"
    forfour="${line::-4}"
    forfour1="${forfour}_1"
    forfour2="${forfour}_2"
    lastdig="${trimmed:${#trimmed}-1}"
    trimmed_1="${trimmed}_1"
    trimmed_2="${trimmed}_2"
    echo $string
    echo $trimmed
    echo $trimmed_1
    echo $trimmed_2

    #/home/nam4021/project/project_org/fastqfiles/$new_name_trim.fastq.gz
    if [ $string =  'LOW_NAFLD4_2' ]; then
    echo "Check for Low 4"
    #echo "$forfor"
    #echo "--readFilesIn $forfour1.fastq.gz $forfour2.fastq.gz"
    #echo "--outFileNamePrefix /home/nam4021/project/project_org/star_NAFLD/$trimmed " \ 

      # Use wget to download the URL specified in the current line
    STAR --runMode alignReads \
     --runThreadN 8 \
     --genomeDir /athena/angsd/scratch/nam4021/hg38_Index  \
     --readFilesCommand gunzip -c \
     --readFilesIn /home/nam4021/project/project_org/fastqfiles/$forfour1.fastq.gz /home/nam4021/project/project_org/fastqfiles/$forfour2.fastq.gz \
     --outFileNamePrefix /athena/angsd/scratch/nam4021/star_NAFLD/$forfour \
     --outSAMtype BAM SortedByCoordinate
    
else
    #echo  "--readFilesIn $trimmed_1.fastq.gz $trimmed_2.fastq.gz"
    #echo  " --outFileNamePrefix /home/nam4021/project/project_org/star_NAFLD/$string " \
      # Use wget to download the URL specified in the current line
    STAR --runMode alignReads \
     --runThreadN 8 \
     --genomeDir /athena/angsd/scratch/nam4021/hg38_Index  \
     --readFilesCommand gunzip -c \
     --readFilesIn /home/nam4021/project/project_org/fastqfiles/$trimmed_1.fastq.gz /home/nam4021/project/project_org/fastqfiles/$trimmed_2.fastq.gz \
     --outFileNamePrefix /athena/angsd/scratch/nam4021/star_NAFLD/$trimmed \
     --outSAMtype BAM SortedByCoordinate
     #--alignIntronMin 31  --alignIntronMax 3000 https://genome.ucsc.edu/cgi-bin/hgTables to an external site.
     # -- outTmpDir /localScratch
fi

done


echo 'Finished'
```

5. Samtools BAM File Indexing 

After this, I used the sam_index.sh script in order to index all the bam files. This doesn't take much processing power, so I've only used 1 node, task and 4G. There really isn't any other customization/parameters needed to be changed here. It's important to make sure the bam.bai files and bam files are within the same folder once indexed.
```
#!/bin/bash

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="sam_index"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=4G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

mamba activate angsd

# Define the directory containing the BAM files
bam_dir="/athena/angsd/scratch/nam4021/star_NAFLD"

# Loop through each BAM file in the directory and index it
for bam_file in "${bam_dir}"/*.bam
do
  samtools index "${bam_file}"
done


# In order words, accomplishes this
#samtools index HIGH_NAFLD1Aligned.sortedByCoord.out.bam
#samtools index HIGH_NAFLD2Aligned.sortedByCoord.out.bam
#samtools index HIGH_NAFLD3Aligned.sortedByCoord.out.bam
#samtools index HIGH_NAFLD4Aligned.sortedByCoord.out.bam
#samtools index LOW_NAFLD1Aligned.sortedByCoord.out.bam
#samtools index LOW_NAFLD2Aligned.sortedByCoord.out.bam
#samtools index LOW_NAFLD3Aligned.sortedByCoord.out.bam
#samtools index LOW_NAFLD4Aligned.sortedByCoord.out.bam
```

6. Alignment QC - BamQC, RSeQC 

Next, I decided to run BamQC and RSeQC. Qorts continued to provide an error due to the annotation file format (GFF3), and I wasn't able to find a conversion that was compatible. Therefore, I decided to run BamQC and RSeQC.

First, it was necessary to convert the gff file to a bed file for RSeQC compatability. In order to run RSEQC, I took my original gff file, and converted it to a gene pred file using bedops package in a mamba environment called gff3tobed.
```
mamba activate gff3tobed
gff2bed < /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40/genomic.gff > /home/nam4021/project/genomic.bed
```

The below script is called QC_and_reads2.sh. For the BamQC, and RSeQC - read distribution and geneBody_coverage functions, few inputs were necessary. Including the BAM file, output directory or file name, and the annotation folder.

```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=4
#SBATCH --job-name="qc_reads"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=24G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

mamba activate rseqc

csv_new_name="new_names.csv"

echo "Starting QC and Reads"

awk 'NR % 2 == 0' "$csv_new_name" | while read line
do
    string="${line::-2}"
    trimmed="${line::-3}"
    forfour="${line::-4}"
    forfour1="${forfour}_1"
    forfour2="${forfour}_2"
    lastdig="${trimmed:${#trimmed}-1}"
    trimmed_1="${trimmed}_1"
    trimmed_2="${trimmed}_2"

    #/home/nam4021/project/project_org/fastqfiles/$new_name_trim.fastq.gz
    if [ $string =  'LOW_NAFLD4_2' ]; then
    echo "Check for Low 4"
    echo "$forfour"

        if [ -e "/athena/angsd/scratch/nam4021/reads/LOW_NAFLD4_body_coverage.out" ]; then
            echo "$forfour exists"

        else
            echo "$forfour does not exist"

            # Issue - not sure why my BAMQC outputs to the /athena/angsd/scratch/nam4021/star_NAFLD/ directory and not the specified QCout
            /softlib/apps/EL7/BamQC/bin/bamqc [-o /athena/angsd/scratch/nam4021/QCout] [-g /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40] /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD4Aligned.sortedByCoord.out.bam
        
            read_distribution.py -i /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD4Aligned.sortedByCoord.out.bam -r /home/nam4021/project/genomic2.bed > /athena/angsd/scratch/nam4021/reads/LOW_NAFLD4_read_distribution.out

            geneBody_coverage.py -r /home/nam4021/project/genomic2.bed -i /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD4Aligned.sortedByCoord.out.bam -o /athena/angsd/scratch/nam4021/reads/LOW_NAFLD4_body_coverage.out
        fi
else
    echo "$trimmed"

    if [ -e "/athena/angsd/scratch/nam4021/reads/"$trimmed"_read_distribution.out" ]; then
        echo "$trimmed exists"

    else
        echo "$trimmed does not exist"


        /softlib/apps/EL7/BamQC/bin/bamqc [-o /athena/angsd/scratch/nam4021/QCout] [-g /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40] /athena/angsd/scratch/nam4021/star_NAFLD/"$trimmed"Aligned.sortedByCoord.out.bam

        read_distribution.py -i /athena/angsd/scratch/nam4021/star_NAFLD/"$trimmed"Aligned.sortedByCoord.out.bam -r /home/nam4021/project/genomic2.bed > /athena/angsd/scratch/nam4021/reads/"$trimmed"_read_distribution.out

        geneBody_coverage.py -r /home/nam4021/project/genomic2.bed -i /athena/angsd/scratch/nam4021/star_NAFLD/"$trimmed"Aligned.sortedByCoord.out.bam -o /athena/angsd/scratch/nam4021/reads/"$trimmed"_body_coverage.out
    fi
fi

done


echo 'Finished'
```

For additional QC, 

7. MultiQC

Using the below command, I brought together all the QC results together into multiqc_report_04_03_2023.html. 
```
mamba activate multiqc
multiqc /athena/angsd/scratch/nam4021/fastqc_NAFLD /athena/angsd/scratch/nam4021/star_NAFLD /athena/angsd/scratch/nam4021/reads -o /athena/angsd/scratch/nam4021/QCout 
```

The FASTQC looks pretty good! The per base sequence content failed due to the first 11-15 bases for each file, which is common for RNA-seq data. Sequence duplication failed as well, but even after de-duplication there were many different sequences found to be duplicated. However, other quality measures showed good quality. Adapter content was very low in the untrimmed fastq file and nothing changed with the trimmed fastqc except for the sequence length distribution changing slightly in my previous analysis (checking the first file from the previous assignment). Therefore, I didn't find the need to use the trimmed.

The quality looks good for genome coverage, chromosome read density and other statistics, but the Mapping Quality histogram shows only around 55-60% of reads in the 248+ quality reads.


For the basic alignment QC, I ran the below commands.
```
(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat HIGH_NAFLD1Aligned.sortedByCoord.out.bam 
164314386 + 0 in total (QC-passed reads + QC-failed reads)
131535322 + 0 primary
32779064 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
164314386 + 0 mapped (100.00% : N/A)
131535322 + 0 primary mapped (100.00% : N/A)
131535322 + 0 paired in sequencing
65767661 + 0 read1
65767661 + 0 read2
131535322 + 0 properly paired (100.00% : N/A)
131535322 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat HIGH_NAFLD2Aligned.sortedByCoord.out.bam 
123334824 + 0 in total (QC-passed reads + QC-failed reads)
101016752 + 0 primary
22318072 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
123334824 + 0 mapped (100.00% : N/A)
101016752 + 0 primary mapped (100.00% : N/A)
101016752 + 0 paired in sequencing
50508376 + 0 read1
50508376 + 0 read2
101016752 + 0 properly paired (100.00% : N/A)
101016752 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat HIGH_NAFLD3Aligned.sortedByCoord.out.bam 
125216540 + 0 in total (QC-passed reads + QC-failed reads)
104052616 + 0 primary
21163924 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
125216540 + 0 mapped (100.00% : N/A)
104052616 + 0 primary mapped (100.00% : N/A)
104052616 + 0 paired in sequencing
52026308 + 0 read1
52026308 + 0 read2
104052616 + 0 properly paired (100.00% : N/A)
104052616 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat HIGH_NAFLD4Aligned.sortedByCoord.out.bam 
139899310 + 0 in total (QC-passed reads + QC-failed reads)
105565702 + 0 primary
34333608 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
139899310 + 0 mapped (100.00% : N/A)
105565702 + 0 primary mapped (100.00% : N/A)
105565702 + 0 paired in sequencing
52782851 + 0 read1
52782851 + 0 read2
105565702 + 0 properly paired (100.00% : N/A)
105565702 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat LOW_NAFLD1Aligned.sortedByCoord.out.bam 
118733936 + 0 in total (QC-passed reads + QC-failed reads)
97770092 + 0 primary
20963844 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
118733936 + 0 mapped (100.00% : N/A)
97770092 + 0 primary mapped (100.00% : N/A)
97770092 + 0 paired in sequencing
48885046 + 0 read1
48885046 + 0 read2
97770092 + 0 properly paired (100.00% : N/A)
97770092 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat LOW_NAFLD2Aligned.sortedByCoord.out.bam 
134677736 + 0 in total (QC-passed reads + QC-failed reads)
110673362 + 0 primary
24004374 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
134677736 + 0 mapped (100.00% : N/A)
110673362 + 0 primary mapped (100.00% : N/A)
110673362 + 0 paired in sequencing
55336681 + 0 read1
55336681 + 0 read2
110673362 + 0 properly paired (100.00% : N/A)
110673362 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat LOW_NAFLD3Aligned.sortedByCoord.out.bam 
121912290 + 0 in total (QC-passed reads + QC-failed reads)
101095978 + 0 primary
20816312 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
121912290 + 0 mapped (100.00% : N/A)
101095978 + 0 primary mapped (100.00% : N/A)
101095978 + 0 paired in sequencing
50547989 + 0 read1
50547989 + 0 read2
101095978 + 0 properly paired (100.00% : N/A)
101095978 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)

(angsd) [nam4021@buddy star_NAFLD]$ samtools flagstat LOW_NAFLD4Aligned.sortedByCoord.out.bam 
131560010 + 0 in total (QC-passed reads + QC-failed reads)
109421558 + 0 primary
22138452 + 0 secondary
0 + 0 supplementary
0 + 0 duplicates
0 + 0 primary duplicates
131560010 + 0 mapped (100.00% : N/A)
109421558 + 0 primary mapped (100.00% : N/A)
109421558 + 0 paired in sequencing
54710779 + 0 read1
54710779 + 0 read2
109421558 + 0 properly paired (100.00% : N/A)
109421558 + 0 with itself and mate mapped
0 + 0 singletons (0.00% : N/A)
0 + 0 with mate mapped to a different chr
0 + 0 with mate mapped to a different chr (mapQ>=5)
```
The alignment looks like it worked well! All of the reads passed the QC test for the total number of reads, the number of mapped reads and the mapping rate. There were no reads mapped as singletons, mapped to different chromosomes or mapped to the same chromosome but on different strands.

8. Read Counts

Finally, I ran the below script, called feature_counts.sh, in order to get the feature counts from all of the corresponding bam files.

For this, there were multiple necessary input parameters to successfully count the features. -s 2 was necessary since the fasta/bam files were reverse stranded. -g gene was necessary to 
```
#!/bin/bash -l

#SBATCH --partition=angsd_class
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --job-name="feature_counts"
#SBATCH --time=24:00:00 # HH/MM/SS
#SBATCH --mem=8G # memory requested, units available: K,M,G,T
#SBATCH --mail-user=nam4021@med.cornell.edu
#SBATCH --mail-type=ALL
#SBATCH --requeue

mamba activate angsd

featureCounts -p --countReadPairs -s 2 \
                -g gene -a /home/nam4021/project/ncbi_dataset/data/GCF_000001405.40/genomic.gff \
                -o /athena/angsd/scratch/nam4021/gene_counts_NAFLD_gene \
              /athena/angsd/scratch/nam4021/star_NAFLD/HIGH_NAFLD1Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/HIGH_NAFLD2Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/HIGH_NAFLD3Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/HIGH_NAFLD4Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD1Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD2Aligned.sortedByCoord.out.bam \                /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD3Aligned.sortedByCoord.out.bam \
              /athena/angsd/scratch/nam4021/star_NAFLD/LOW_NAFLD4Aligned.sortedByCoord.out.bam
```

Then I used scp to transfer the output from on the scratch directory to my local computer.

In the next Rmd and html files, called Read_counts_NAFLD.rmd and .html, I proceed to take this output and input it into R!

9. Mamba environments

All the mamba environments used for this analysis are available in the Mamba environments folder.
From: mamba env list:
```
# conda environments:
#
angsd                    /athena/angsd/scratch/mef3005/share/envs/angsd
multiqc                  /athena/angsd/scratch/mef3005/share/envs/multiqc
qorts                    /athena/angsd/scratch/mef3005/share/envs/qorts
r42-deseq                /athena/angsd/scratch/mef3005/share/envs/r42-deseq
rseqc                    /athena/angsd/scratch/mef3005/share/envs/rseqc
trim-galore              /athena/angsd/scratch/mef3005/share/envs/trim-galore
base                     /pbtech_mounts/homes064/nam4021/mambaforge
gff3tobed             *  /pbtech_mounts/homes064/nam4021/mambaforge/envs/gff3tobed
```
I created the yml min and full lists using the below commands. Replacing venv with each of the conda environments above
```
mamba env export -n venv --from-history > /home/nam4021/project/project_org/mamba_env/venv.min.yaml
mamba env export -n venv > /home/nam4021/project/project_org/mamba_env/venv.full.yaml

scp -r nam4021@aphrodite.med.cornell.edu://home/nam4021/project/project_org/mamba_env /Users/johnmorris/Desktop/Comp_Bio_MS_Weill_Cornell/Spring_2023/ANGSD/Project_Download/ANGSD_NAFLD_Project_2023/Mamba\ Environments
```

